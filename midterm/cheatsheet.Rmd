---
output: 
  pdf_document:
    template: template.tex
---
Midterm Cheatsheet

\textbf{Bayes' Rule for Events}

\large$P(B |A) = \frac{P(A \cap B)}{P(A)} = \frac{P(A|B)P(B)}{P(A)}$

where, by the Law of Total Probability,     

$P(A) = P(A|B)P(B) + P(A|B^c)P(B^c)$

\textbf{Posterior Model}

\large$f(\pi|y) = \frac{f(\pi)L(\pi|y)}{f(y)} \propto f(\pi)L(\pi|y)$

\textbf{Beta Model}

$\pi \sim \text{Beta} (\alpha, \beta)$

The Beta model is specified by continuous pdf

$f(\pi) = \frac{\Gamma(\alpha + \beta)}{\Gamma(\alpha)\Gamma(\beta)} \pi^{\alpha-1} (1-\pi)^{\beta-1} \;\; \text{ for } \pi \in [0,1], \alpha >0, \text{and } \beta>0$

 where $\Gamma(z) = \int_0^\infty x^{z-1}e^{-x}dx$ and $\Gamma(z + 1) = z \Gamma(z)$.  Fun fact: when $z$ is a positive integer, then $\Gamma(z)$ simplifies to $\Gamma(z) = (z-1)!$.   
 
 
\textbf{Beta Descriptives}
 
 $E(\pi) = \frac{\alpha}{\alpha + \beta}$

$\text{Mode}(\pi) = \frac{\alpha - 1}{\alpha + \beta - 2}$  

$\text{Var}(\pi) = \frac{\alpha \beta}{(\alpha + \beta)^2(\alpha + \beta + 1)}$


\textbf{The Beta-Binomial Model}

Let $\pi \sim \text{Beta}(\alpha, \beta)$ and $X|n \sim \text{Bin}(n,\pi)$ then

$\pi|(Y=y) \sim \text{Beta}(\alpha+y, \beta+n-y)$


\newpage

\textbf{Gamma Prior}



$\lambda \sim \text{Gamma}(s, r)$  where $s > 0$ and
$r > 0$: 

The Gamma distribution is specified by continuous pdf
\large$f(\lambda) = \frac{r^s}{\Gamma(s)} \lambda^{s-1} e^{-r\lambda} \;\; \text{ for } \lambda \in [0,\infty)$

\textbf{Gamma Descriptives}


$E(\lambda) = \frac{s}{r}$

$\text{Mode}(\lambda) = \frac{s - 1}{r} \text{ where } s\ge1$ 

$\text{Var}(\lambda) = \frac{s}{r^2}$

\textbf{Poisson Likelihood}

$f(y|\lambda) =  \frac{e^{-\lambda}\lambda^y}{y!}\;\; \text{ for } y \in \{0,1,2,\ldots,n\}$


\textbf{The Gamma-Poisson Model}

If $f(\lambda) \sim \text{Gamma}(s, r)$   

and if $y_i \sim iid \text{ Poissson}(\lambda) \text{for } i \in 1,\ldots ,n$ 

then $f(\lambda|\vec{y}) \sim \text{Gamma}(s+ \sum y_i, r+n)$.


\newpage

\textbf{Normal Prior}

If $\mu \sim N(\theta, \tau^2)$ then

\begin{equation}
f(\mu) = \frac{1}{\sqrt{2\pi\tau^2}} \exp\bigg[{-\frac{(\mu - \theta)^2}{2\tau^2}}\bigg] \;\; \text{ for } \mu \in (-\infty,\infty) \; .
\end{equation}


\textbf{Normal Likelihood}

If $Y \sim N(\mu, \sigma^2)$ then

\begin{equation}
f(y) = \frac{1}{\sqrt{2\pi\sigma^2}} \exp\bigg[{-\frac{(y-\mu)^2}{2\sigma^2}}\bigg] \;\; \text{ for } y \in (-\infty,\infty)
\end{equation}

$$L(\mu |\vec{y}) \propto \prod_{i=1}^{n} \exp\bigg[{-\frac{(y_i-\mu)^2}{2\sigma^2}}\bigg] =  \exp\bigg[{-\frac{\sum_{i=1}^n (y_i-\mu)^2}{2\sigma^2}}\bigg] \; .$$

\textbf{The Normal Posterior}

If 

$$\begin{split}
Y_i | \mu & \stackrel{ind}{\sim} N(\mu, \sigma^2) \\
\mu & \sim N(\theta, \tau^2) \\
\end{split}$$

then

\begin{equation}
\mu|\vec{y} \; \sim \;  N\bigg(\frac{\theta\sigma^2/n + \bar{y}\tau^2}{\tau^2+\sigma^2/n}, \; \frac{\tau^2\sigma^2/n}{\tau^2+\sigma^2/n}\bigg) \; .
\end{equation}