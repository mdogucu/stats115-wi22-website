<!DOCTYPE html>
<html lang="" xml:lang="">
  <head>
    <title>Simple Normal Regression</title>
    <meta charset="utf-8" />
    <meta name="author" content="Dr. Mine Dogucu" />
    <script src="slide-07a-snr_files/header-attrs-2.11/header-attrs.js"></script>
    <link rel="stylesheet" href="slide-style.css" type="text/css" />
  </head>
  <body>
    <textarea id="source">


class: title-slide







&lt;br&gt;
&lt;br&gt;
.right-panel[ 

# Simple Normal Regression
## Dr. Mine Dogucu
Examples from [bayesrulesbook.com](https://bayesrulesbook.com)

]

---


```r
glimpse(bikes)
```

```
## Rows: 500
## Columns: 13
## $ date        &lt;date&gt; 2011-01-01, 2011-01-03, 2011-01-04, 2011-01-05, 20…
## $ season      &lt;fct&gt; winter, winter, winter, winter, winter, winter, win…
## $ year        &lt;int&gt; 2011, 2011, 2011, 2011, 2011, 2011, 2011, 2011, 201…
## $ month       &lt;fct&gt; Jan, Jan, Jan, Jan, Jan, Jan, Jan, Jan, Jan, Jan, J…
## $ day_of_week &lt;fct&gt; Sat, Mon, Tue, Wed, Fri, Sat, Mon, Tue, Wed, Thu, F…
## $ weekend     &lt;lgl&gt; TRUE, FALSE, FALSE, FALSE, FALSE, TRUE, FALSE, FALS…
## $ holiday     &lt;fct&gt; no, no, no, no, no, no, no, no, no, no, no, no, no,…
## $ temp_actual &lt;dbl&gt; 57.39952, 46.49166, 46.76000, 48.74943, 46.50332, 4…
## $ temp_feel   &lt;dbl&gt; 64.72625, 49.04645, 51.09098, 52.63430, 50.79551, 4…
## $ humidity    &lt;dbl&gt; 80.5833, 43.7273, 59.0435, 43.6957, 49.8696, 53.583…
## $ windspeed   &lt;dbl&gt; 10.749882, 16.636703, 10.739832, 12.522300, 11.3046…
## $ weather_cat &lt;fct&gt; categ2, categ1, categ1, categ1, categ2, categ2, cat…
## $ rides       &lt;int&gt; 654, 1229, 1454, 1518, 1362, 891, 1280, 1220, 1137,…
```

---

## Rides

.pull-left[


&lt;img src="slide-07a-snr_files/figure-html/unnamed-chunk-4-1.png" style="display: block; margin: auto;" /&gt;

]

.pull-right[

`\(Y_i | \mu, \sigma  \stackrel{ind}{\sim} N(\mu, \sigma^2)\)`  
`\(\mu \sim N(\theta, \tau^2)\)`
`\(\sigma  \sim \text{ some prior model.}\)`

]

---

class: middle 

## Regression Model

`\(Y_i\)` the number of rides  
`\(X_i\)` temperature (in Fahrenheit) on day `\(i\)`. 

--

`\(\mu_i = \beta_0 + \beta_1X_i\)`

--

`\(\beta_0:\)` the typical ridership on days in which the temperature was 0 degrees ( `\(X_i\)`=0). It is not interpretable in this case.

`\(\beta_1:\)` the typical change in ridership for every one unit increase in temperature.

---

### Normal likelihood model

\begin{split}
Y_i | \beta_0, \beta_1, \sigma &amp; \stackrel{ind}{\sim} N\left(\mu_i, \sigma^2\right) \;\; \text{ with } \;\; \mu_i = \beta_0 + \beta_1X_i \; .\\
\end{split}

&lt;img src="slide-07a-snr_files/figure-html/ch-9-normal-assumptions-1.png" style="display: block; margin: auto;" /&gt;

These simulations show two cases where `\(\beta_0 = -2000\)` and slope `\(\beta_1 = 100\)`.
On the left `\(\sigma = 2000\)` and on the right `\(\sigma = 200\)` (right). In both cases, the model line is defined by `\(\beta_0 + \beta_1 x = -2000 + 100 x\)`.


---

## Prior Models

`\(\text{likelihood model:} \; \; \; Y_i | \beta_0, \beta_1, \sigma \;\;\;\stackrel{ind}{\sim} N\left(\mu_i, \sigma^2\right)\text{ with } \mu_i = \beta_0 + \beta_1X_i\)`

`\(\text{prior models:}\)` 

`\(\beta_0\sim N(m_0, s_0^2 )\)`  
`\(\beta_1\sim N(m_1, s_1^2 )\)`  
`\(\sigma \sim \text{Exp}(l)\)`

--

Recall: 

`\(\text{Exp}(l) = \text{Gamma}(1, l)\)`

---

class: middle

## Prior Models

`$$\begin{split}
Y_i | \beta_0, \beta_1, \sigma &amp; \stackrel{ind}{\sim} N\left(\mu_i, \sigma^2\right) \;\; \text{ with } \;\; \mu_i = \beta_0 + \beta_1X_i \\
\beta_0  &amp; \sim N\left(3482, 3937^2 \right)  \\
\beta_1  &amp; \sim N\left(0, 351^2 \right) \\
\sigma   &amp; \sim \text{Exp}(0.00064) \; .\\
\end{split}$$`


---

class: middle


```r
plot_normal(mean = 5000, sd = 1000) + 
  labs(x = "beta_0c", y = "pdf")
```

&lt;img src="slide-07a-snr_files/figure-html/unnamed-chunk-5-1.png" style="display: block; margin: auto;" /&gt;

---

class: middle



```r
plot_normal(mean = 100, sd = 40) + 
  labs(x = "beta_1", y = "pdf")
```

&lt;img src="slide-07a-snr_files/figure-html/unnamed-chunk-6-1.png" style="display: block; margin: auto;" /&gt;

---

class: middle



```r
plot_gamma(shape = 1, rate = 0.0008) + 
  labs(x = "sigma", y = "pdf")
```

&lt;img src="slide-07a-snr_files/figure-html/unnamed-chunk-7-1.png" style="display: block; margin: auto;" /&gt;

---


class: middle

`$$\begin{split}
Y_i | \beta_0, \beta_1, \sigma &amp; \stackrel{ind}{\sim} N\left(\mu_i, \sigma^2\right) \;\; \text{ with } \;\; \mu_i = \beta_0 + \beta_1X_i \\
\beta_{0c}  &amp; \sim N\left(5000, 1000^2 \right)  \\
\beta_1  &amp; \sim N\left(100, 40^2 \right) \\
\sigma   &amp; \sim \text{Exp}(0.0008)  .\\
\end{split}$$`

---

class: middle 

&lt;img src="slide-07a-snr_files/figure-html/unnamed-chunk-8-1.png" style="display: block; margin: auto;" /&gt;

---

class: middle

## Simulation via `rstanarm`


```r
bike_model &lt;- stan_glm(rides ~ temp_feel, data = bikes,
                       family = gaussian,
                       prior_intercept = normal(5000, 1000),
                       prior = normal(100, 40), 
                       prior_aux = exponential(0.0008),
                       chains = 4, iter = 5000*2, seed = 84735,
                       refresh = FALSE) 
```

The `refresh = FALSE` prevents printing out your chains and iterations, especially useful in R Markdown.

---

class: middle


```r
# Effective sample size ratio and Rhat
neff_ratio(bike_model)
```

```
## (Intercept)   temp_feel       sigma 
##     1.04185     1.03700     1.00360
```

```r
rhat(bike_model)
```

```
## (Intercept)   temp_feel       sigma 
##   0.9999203   0.9999217   1.0000107
```

The effective sample size ratios are slightly above 1 and the R-hat values are very close to 1, indicating that the chains are stable, mixing quickly, and behaving much like an independent sample.

---

class: middle


```r
mcmc_trace(bike_model, size = 0.1)
```

&lt;img src="slide-07a-snr_files/figure-html/unnamed-chunk-11-1.png" style="display: block; margin: auto;" /&gt;

---

class: middle



```r
mcmc_dens_overlay(bike_model)
```

&lt;img src="slide-07a-snr_files/figure-html/unnamed-chunk-12-1.png" style="display: block; margin: auto;" /&gt;

---


```r
# STEP 1: DEFINE the model
stan_bike_model &lt;- "
  data {
    int&lt;lower = 0&gt; n;
    vector[n] Y;
    vector[n] X;
  }
  parameters {
    real beta0;
    real beta1;
    real&lt;lower = 0&gt; sigma;
  }
  model {
    Y ~ normal(beta0 + beta1 * X, sigma);
    beta0 ~ normal(-2000, 1000);
    beta1 ~ normal(100, 40);
    sigma ~ exponential(0.0008);
  }
"
```

---

class: middle


```r
# STEP 2: SIMULATE the posterior
stan_bike_sim &lt;- 
  stan(model_code = stan_bike_model, 
       data = list(n = nrow(bikes), Y = bikes$rides, X = bikes$temp_feel), 
       chains = 4, iter = 5000*2, seed = 84735, refresh = FALSE)
```

---


```r
broom.mixed::tidy(bike_model, effects = c("fixed", "aux"),
     conf.int = TRUE, conf.level = 0.80)
```

```
## # A tibble: 4 × 5
##   term        estimate std.error conf.low conf.high
##   &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;
## 1 (Intercept)  -2194.     362.    -2656.    -1732. 
## 2 temp_feel       82.2      5.15     75.6      88.8
## 3 sigma         1281.      40.7    1231.     1336. 
## 4 mean_PPD      3487.      80.4    3385.     3591.
```




Referring to the `tidy()` summary, the __posterior median relationship__ is

`$$\begin{equation}
-2194.24 + 82.16 X
\end{equation}$$`

---

class: middle


```r
# Store the 4 chains for each parameter in 1 data frame
bike_model_df &lt;- as.data.frame(bike_model)
# Check it out
nrow(bike_model_df)
```

```
## [1] 20000
```

```r
head(bike_model_df, 3)
```

```
##   (Intercept) temp_feel    sigma
## 1   -2656.894  88.16061 1323.364
## 2   -2188.090  83.01252 1322.962
## 3   -1983.816  81.53971 1363.346
```

---

class: middle


```r
# 50 simulated model lines
bikes %&gt;%
  tidybayes::add_fitted_draws(bike_model, n = 50) %&gt;%
  ggplot(aes(x = temp_feel, y = rides)) +
    geom_line(aes(y = .value, group = .draw), alpha = 0.15) + 
    geom_point(data = bikes, size = 0.05)
```

&lt;img src="slide-07a-snr_files/figure-html/unnamed-chunk-18-1.png" style="display: block; margin: auto;" /&gt;


---


class: middle 


```r
# Tabulate the beta_1 values that exceed 0
bike_model_df %&gt;% 
  mutate(exceeds_0 = temp_feel &gt; 0) %&gt;% 
  tabyl(exceeds_0)
```

```
##  exceeds_0     n percent
##       TRUE 20000       1
```


---

class: middle

## Posterior Prediction

Suppose a weather report indicates that tomorrow will be a 75-degree day in D.C. What's your posterior guess of the number of riders that Capital Bikeshare should anticipate?


---

class: middle




Your natural first crack at this question might be to plug the 75-degree temperature into the posterior median model.
Thus, we expect that there will be 3968 riders tomorrow:

`$$-2194.24 + 82.16*75 = 3967.76$$`

--

Not quiet.

---

class: middle

Recall that this singular prediction ignores two potential sources of variability:

- __Sampling variability__ in the data    
    The observed ridership outcomes, `\(Y\)`, typically _deviate_ from the model line. That is, we don't expect every 75-degree day to have the same exact number of rides.
    
--
    
- __Posterior variability__ in parameters `\((\beta_0, \beta_1, \sigma)\)`    

The posterior median model is merely the center in a _range_ of plausible model lines `\(\beta_0 + \beta_1 X\)`. We should consider this entire range as well as that in `\(\sigma\)`, the degree to which observations might deviate from the model lines.

--

The __posterior predictive model__ of a new data point `\(Y_{\text{new}}\)` accounts for both sources of variability.


---

We have20,000 sets of parameters in the Markov chain `\(\left(\beta_0^{(i)},\beta_1^{(i)},\sigma^{(i)}\right)\)`.
We can then _approximate_ the posterior predictive model for `\(Y_{\text{new}}\)` at `\(X = 75\)` by simulating a ridership prediction from the Normal model evaluated each parameter set:

`$$Y_{\text{new}}^{(i)} | \beta_0, \beta_1, \sigma  \; \sim \; N\left(\mu^{(i)}, \left(\sigma^{(i)}\right)^2\right) \;\; \text{ with } \;\; \mu^{(i)} = \beta_0^{(i)} + \beta_1^{(i)} \cdot 75.$$`
--

`$$\left[
\begin{array}{lll} 
\beta_0^{(1)} &amp; \beta_1^{(1)} &amp; \sigma^{(1)} \\
\beta_0^{(2)} &amp; \beta_1^{(2)} &amp; \sigma^{(2)} \\
\vdots &amp; \vdots &amp; \vdots \\
\beta_0^{(20000)} &amp; \beta_1^{(20000)} &amp; \sigma^{(20000)} \\
\end{array}
\right]
\;\; \longrightarrow \;\;
\left[
\begin{array}{l} 
Y_{\text{new}}^{(1)} \\
Y_{\text{new}}^{(2)} \\
\vdots \\
Y_{\text{new}}^{(20000)} \\
\end{array}
\right]$$`


---

class: middle 


```r
first_set &lt;- head(bike_model_df, 1)
first_set
```

```
##   (Intercept) temp_feel    sigma
## 1   -2656.894  88.16061 1323.364
```


---

class: middle 


```r
mu &lt;- first_set$`(Intercept)` + first_set$temp_feel * 75
mu
```

```
## [1] 3955.152
```


---

class: middle 



```r
set.seed(84735)
y_new &lt;- rnorm(1, mean = mu, sd = first_set$sigma)
y_new
```

```
## [1] 4838.144
```

---

class: middle 


```r
# Predict rides for each parameter set in the chain
set.seed(84735)
predict_75 &lt;- bike_model_df %&gt;% 
  mutate(mu = `(Intercept)` + temp_feel*75,
         y_new = rnorm(20000, mean = mu, sd = sigma))
```



```r
head(predict_75, 3)
```

```
##   (Intercept) temp_feel    sigma       mu    y_new
## 1   -2656.894  88.16061 1323.364 3955.152 4838.144
## 2   -2188.090  83.01252 1322.962 4037.849 3874.013
## 3   -1983.816  81.53971 1363.346 4131.662 5196.255
```

---

class: middle 


```r
# Construct 80% posterior credible intervals
predict_75 %&gt;% 
  summarize(lower_mu = quantile(mu, 0.025),
            upper_mu = quantile(mu, 0.975),
            lower_new = quantile(y_new, 0.025),
            upper_new = quantile(y_new, 0.975))
```

```
##   lower_mu upper_mu lower_new upper_new
## 1 3843.027 4094.863  1499.832  6482.125
```


---

class: middle 


```r
# Plot the posterior model of the typical ridership on 75 degree days
ggplot(predict_75, aes(x = mu)) + 
  geom_density()
# Plot the posterior predictive model of tomorrow's ridership
ggplot(predict_75, aes(x = y_new)) + 
  geom_density()
```


---

class: middle 

&lt;img src="slide-07a-snr_files/figure-html/ch9-post-pred-1.png" style="display: block; margin: auto;" /&gt;

---

class: middle 

## Posterior Prediction with rstanarm


```r
# Simulate a set of predictions
set.seed(84735)
shortcut_prediction &lt;- 
  posterior_predict(bike_model, newdata = data.frame(temp_feel = 75))
```


```r
head(shortcut_prediction, 3)
```

```
##             1
## [1,] 4838.144
## [2,] 3874.013
## [3,] 5196.255
```

---

class: middle 



```r
# Construct a 95% posterior credible interval
posterior_interval(shortcut_prediction, prob = 0.95)
```

```
##       2.5%    97.5%
## 1 1499.832 6482.125
```

---

class: middle 


```r
# Plot the approximate predictive model
mcmc_dens(shortcut_prediction) + 
  xlab("predicted ridership on a 75 degree day")
```

&lt;img src="slide-07a-snr_files/figure-html/unnamed-chunk-31-1.png" style="display: block; margin: auto;" /&gt;

---

class: middle

## Using the default priors in `rstanarm`


```r
bike_model_default &lt;- stan_glm(
  rides ~ temp_feel, data = bikes, 
  family = gaussian,
  prior_intercept = normal(5000, 2.5, autoscale = TRUE),
  prior = normal(0, 2.5, autoscale = TRUE), 
  prior_aux = exponential(1, autoscale = TRUE),
  chains = 4, iter = 5000*2, seed = 84735, refresh=FALSE)
```

By setting `autoscale = TRUE`, `stan_glm()` adjusts or scales our default priors to optimize the study of parameters which have different scales.

---

class: middle


```r
prior_summary(bike_model_default)
```

```
## Priors for model 'bike_model_default' 
## ------
## Intercept (after predictors centered)
##   Specified prior:
##     ~ normal(location = 5000, scale = 2.5)
##   Adjusted prior:
##     ~ normal(location = 5000, scale = 3937)
## 
## Coefficients
##   Specified prior:
##     ~ normal(location = 0, scale = 2.5)
##   Adjusted prior:
##     ~ normal(location = 0, scale = 351)
## 
## Auxiliary (sigma)
##   Specified prior:
##     ~ exponential(rate = 1)
##   Adjusted prior:
##     ~ exponential(rate = 0.00064)
## ------
## See help('prior_summary.stanreg') for more details
```


---

class: middle

## Default vs non-default priors

Con: weakly informative priors are tuned with information from the data (through a fairly minor consideration of scale). 

Pro: Unless we have strong prior information, utilizing the defaults will typically lead to more stable simulation results than if we tried tuning our own vague priors.

Pro: The defaults can help us get up and running with Bayesian modeling. In future lectures, we’ll often utilize the defaults in order to focus on the new modeling concepts.



    </textarea>
<style data-target="print-only">@media screen {.remark-slide-container{display:block;}.remark-slide-scaler{box-shadow:none;}}</style>
<script src="https://remarkjs.com/downloads/remark-latest.min.js"></script>
<script>var slideshow = remark.create({
"ratio": "16:9",
"highlightStyle": "pygments",
"highlightLines": true,
"highlightLanguage": "r"
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
  window.dispatchEvent(new Event('resize'));
});
(function(d) {
  var s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
  if (!r) return;
  s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
  d.head.appendChild(s);
})(document);

(function(d) {
  var el = d.getElementsByClassName("remark-slides-area");
  if (!el) return;
  var slide, slides = slideshow.getSlides(), els = el[0].children;
  for (var i = 1; i < slides.length; i++) {
    slide = slides[i];
    if (slide.properties.continued === "true" || slide.properties.count === "false") {
      els[i - 1].className += ' has-continuation';
    }
  }
  var s = d.createElement("style");
  s.type = "text/css"; s.innerHTML = "@media print { .has-continuation { display: none; } }";
  d.head.appendChild(s);
})(document);
// delete the temporary CSS (for displaying all slides initially) when the user
// starts to view slides
(function() {
  var deleted = false;
  slideshow.on('beforeShowSlide', function(slide) {
    if (deleted) return;
    var sheets = document.styleSheets, node;
    for (var i = 0; i < sheets.length; i++) {
      node = sheets[i].ownerNode;
      if (node.dataset["target"] !== "print-only") continue;
      node.parentNode.removeChild(node);
    }
    deleted = true;
  });
})();
(function() {
  "use strict"
  // Replace <script> tags in slides area to make them executable
  var scripts = document.querySelectorAll(
    '.remark-slides-area .remark-slide-container script'
  );
  if (!scripts.length) return;
  for (var i = 0; i < scripts.length; i++) {
    var s = document.createElement('script');
    var code = document.createTextNode(scripts[i].textContent);
    s.appendChild(code);
    var scriptAttrs = scripts[i].attributes;
    for (var j = 0; j < scriptAttrs.length; j++) {
      s.setAttribute(scriptAttrs[j].name, scriptAttrs[j].value);
    }
    scripts[i].parentElement.replaceChild(s, scripts[i]);
  }
})();
(function() {
  var links = document.getElementsByTagName('a');
  for (var i = 0; i < links.length; i++) {
    if (/^(https?:)?\/\//.test(links[i].getAttribute('href'))) {
      links[i].target = '_blank';
    }
  }
})();
// adds .remark-code-has-line-highlighted class to <pre> parent elements
// of code chunks containing highlighted lines with class .remark-code-line-highlighted
(function(d) {
  const hlines = d.querySelectorAll('.remark-code-line-highlighted');
  const preParents = [];
  const findPreParent = function(line, p = 0) {
    if (p > 1) return null; // traverse up no further than grandparent
    const el = line.parentElement;
    return el.tagName === "PRE" ? el : findPreParent(el, ++p);
  };

  for (let line of hlines) {
    let pre = findPreParent(line);
    if (pre && !preParents.includes(pre)) preParents.push(pre);
  }
  preParents.forEach(p => p.classList.add("remark-code-has-line-highlighted"));
})(document);</script>

<script>
slideshow._releaseMath = function(el) {
  var i, text, code, codes = el.getElementsByTagName('code');
  for (i = 0; i < codes.length;) {
    code = codes[i];
    if (code.parentNode.tagName !== 'PRE' && code.childElementCount === 0) {
      text = code.textContent;
      if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
          /^\$\$(.|\s)+\$\$$/.test(text) ||
          /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
        code.outerHTML = code.innerHTML;  // remove <code></code>
        continue;
      }
    }
    i++;
  }
};
slideshow._releaseMath(document);
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>
